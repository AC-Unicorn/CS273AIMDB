{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS as esw\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from glove.src import *\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "class wordSpace:\n",
    "    \n",
    "    def __init__(self, rootPath):\n",
    "        \"\"\"define the whole word space\"\"\"\n",
    "        self.stopWords = {'the' ,\n",
    "                            'a' ,\n",
    "                            'and' ,\n",
    "                            'of' ,\n",
    "                            'this' ,\n",
    "                            'is' ,\n",
    "                            'to' ,\n",
    "                            'i' ,\n",
    "                            'it' ,\n",
    "                            'in' ,\n",
    "                            'was' ,\n",
    "                            'that' ,\n",
    "                            'for' ,\n",
    "                            'but' ,\n",
    "                            'you' ,\n",
    "                            'as' ,\n",
    "                            'with' ,\n",
    "                            'film' ,\n",
    "                            'not' ,\n",
    "                            'have' ,\n",
    "                            'one' ,\n",
    "                            '/><br' ,\n",
    "                            'on' ,\n",
    "                            'be' ,\n",
    "                            'are' ,\n",
    "                            \"it's\"}\n",
    "        self.data = {}\n",
    "        self.vocabSize = 0\n",
    "        self.threshold = 1000\n",
    "        self.tranData, self.testData = self.loadData(rootPath)\n",
    "        \n",
    "        print(\"the wordSpace has been created!\")\n",
    "\n",
    "    def cross_validation(self):\n",
    "        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(self.data[\"train\"][\"text\"], \n",
    "                                                            self.data[\"train\"][\"sentiment\"], test_size=0.2, random_state=0)\n",
    "\n",
    "    def stringTrim(self, content):\n",
    "        temp = content.split(\" \")\n",
    "        newContent = \"\"\n",
    "        for word in temp:\n",
    "            if word in self.stopWords:\n",
    "                pass\n",
    "            else:\n",
    "                newContent += word + \" \"\n",
    "        return newContent\n",
    "    def loadData(self, root):\n",
    "        for folder in ['train','test']:\n",
    "            self.data[folder] = []\n",
    "            for subf in ['pos','neg']:\n",
    "                score = 1 if subf == 'pos' else 0\n",
    "                path = os.path.join(root, folder, subf)\n",
    "                files = os.listdir(path)\n",
    "                print('loading %s' % path)\n",
    "                for file in files:\n",
    "                    with open(os.path.join(path, file), \"r\",encoding = 'ISO-8859-1') as f:\n",
    "                        content = self.stringTrim(f.read())\n",
    "                        wordCount = len(content.split(\" \"))\n",
    "                        if (wordCount < self.threshold):\n",
    "\n",
    "                            self.data[folder].append([content, score, wordCount])\n",
    "        np.random.shuffle(self.data['train'])\n",
    "        self.data[\"train\"] = pd.DataFrame(self.data[\"train\"],\n",
    "                                          columns=['text', 'sentiment','wordCount'])\n",
    "\n",
    "        np.random.shuffle(self.data['test'])\n",
    "        self.data[\"test\"] = pd.DataFrame(self.data[\"test\"],\n",
    "                                    columns=['text', 'sentiment','wordCount'])\n",
    "        return self.data[\"train\"], self.data[\"test\"]\n",
    "    def vectorize(self, model = None):\n",
    "        print('start vectorize')\n",
    "        self.vectorize = CountVectorizer(stop_words = self.stopWords)\n",
    "        \n",
    "        self.training_features = self.vectorize.fit_transform(self.X_train)\n",
    "        self.vali_features = self.vectorize.transform(self.X_test)\n",
    "        \n",
    "        print (self.training_features.shape)\n",
    "        print (self.vali_features.shape)\n",
    "        self.test_features = self.vectorize.transform(self.testData[\"text\"])\n",
    "        \n",
    "        print ('vectorize complete!')\n",
    "    def predictSVM(self):\n",
    "        # Training\n",
    "        model = LinearSVC()\n",
    "        model.fit(self.training_features, self.y_train)\n",
    "        \n",
    "        y_trainhat = model.predict(self.training_features)\n",
    "        train_acc = accuracy_score(self.y_train, y_trainhat)\n",
    "        print(\"Accuracy on the IMDB train dataset using SVM: {:.2f}\".format(train_acc * 100))\n",
    "        \n",
    "        y_validation = model.predict(self.vali_features)\n",
    "        vali_acc = accuracy_score(self.y_test, y_validation)\n",
    "        print(\"Accuracy on the IMDB validation dataset using SVM: {:.2f}\".format(vali_acc * 100))\n",
    "        \n",
    "        y_pred = model.predict(self.test_features)\n",
    "        # Evaluation\n",
    "        acc = accuracy_score(self.testData[\"sentiment\"], y_pred)\n",
    "        print(\"Accuracy on the IMDB dataset using SVM: {:.2f}\".format(acc * 100))\n",
    "    def predictLogistic(self):\n",
    "        log_reg = LogisticRegression(verbose=1, solver='liblinear',random_state=0, C=5, penalty='l2',max_iter=1000)\n",
    "        model = log_reg.fit(self.training_features, self.y_train)\n",
    "        \n",
    "        y_trainhat = model.predict(self.training_features)\n",
    "        train_acc = accuracy_score(self.y_train, y_trainhat)\n",
    "        print(\"Accuracy on the IMDB train dataset using Logistic: {:.2f}\".format(train_acc * 100))\n",
    "        \n",
    "        y_validation = model.predict(self.vali_features)\n",
    "        vali_acc = accuracy_score(self.y_test, y_validation)\n",
    "        print(\"Accuracy on the IMDB validation dataset using Logistic: {:.2f}\".format(vali_acc * 100))\n",
    "        \n",
    "        y_pred = model.predict(self.test_features)\n",
    "        # Evaluation\n",
    "        acc = accuracy_score(self.testData[\"sentiment\"], y_pred)\n",
    "        print(\"\\nAccuracy on the IMDB dataset using Logistic Regression: {:.2f}\".format(acc * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading ./../train/pos\n",
      "loading ./../train/neg\n",
      "loading ./../test/pos\n",
      "loading ./../test/neg\n",
      "the wordSpace has been created!\n"
     ]
    }
   ],
   "source": [
    "words = wordSpace('./../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "words.cross_validation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start vectorize\n",
      "(1676, 9703)\n",
      "(420, 9703)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['br'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vectorize complete!\n"
     ]
    }
   ],
   "source": [
    "words.vectorize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]Accuracy on the IMDB train dataset using Logistic: 100.00\n",
      "Accuracy on the IMDB validation dataset using Logistic: 86.67\n",
      "\n",
      "Accuracy on the IMDB dataset using Logistic Regression: 84.18\n",
      "Accuracy on the IMDB train dataset using SVM: 100.00\n",
      "Accuracy on the IMDB validation dataset using SVM: 86.43\n",
      "Accuracy on the IMDB dataset using SVM: 83.47\n"
     ]
    }
   ],
   "source": [
    "words.predictLogistic()\n",
    "words.predictSVM()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
